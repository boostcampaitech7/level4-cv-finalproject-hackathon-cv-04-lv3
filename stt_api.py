import os
import shutil
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from STT import ClovaSpeechClient
from Emotion import process_func_batch
from utils import *


# FastAPI ê°ì²´ ìƒì„±
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ì—ì„œ í—ˆìš© (ë³´ì•ˆì´ í•„ìš”í•˜ë©´ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ ê°€ëŠ¥)
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš© (GET, POST ë“±)
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

stt_result = None

@app.post("/stt/")
async def speech_to_text(file: UploadFile = File(...)):
    global stt_result

    temp_file_path = f"./temp_{file.filename}"

    with open(temp_file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    try:
        response = ClovaSpeechClient().req_upload(file=temp_file_path, completion='sync')
        result_json = response.json()
        stt_result = preprocess_STT_data(result_json)
    except Exception as e:
        print("STT ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", e)

    return stt_result

@app.post("/emotion/")
async def emotion_recognition(file: UploadFile = File(...)):
    if stt_result is None:
        return {"error": "STT ë³€í™˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    temp_file_path = f"./temp_{file.filename}"

    try:
        sound_numpy = convert_with_ffmpeg_python(temp_file_path)
        sliced_sounds = slice_audio_numpy(sound_numpy, stt_result)
        emotion_predictions = process_func_batch(sliced_sounds)
        for emotion in emotion_predictions:
            print(emotion)

    except Exception as e:
        print("ğŸš¨ Emotion ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return {"error": str(e)}

    finally:
        os.remove(temp_file_path)

    return emotion_predictions



if __name__ == '__main__':
    uvicorn.run(app, host="0.0.0.0", port=30066)
